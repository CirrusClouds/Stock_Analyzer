import scrapy
import dateparser as dt
from ..items import StockscraperItem


class BitcoinDailySpider(scrapy.Spider):
    name = 'btcusd-daily'
    start_urls = ['https://uk.investing.com/crypto/bitcoin/historical-data']

    def start_requests(self,response):
        pass

    def parse(self, response):
        pages = response.xpath('.//body/tr')
        for p in pages:
            info = response.xpath('.//td/text()').getall()
            date = info[0]
            date = dt.parse(date_string=date, settings={"DATE_ORDER": "DMY"}).strftime("%Y-%m-%d")
            current_price = info[1]
            high_price = info[3]
            low_price = info[4]
            volume = info[5]

            item = StockscraperItem(lowprice=low_price, highprice=high_price, date=date, volume=volume, curprice=current_price,)
        yield item
